{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuzman/anaconda3/envs/tensorflow_2/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)]\n",
    "y = iris.target == 0\n",
    "\n",
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-beta1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x7f256663c400>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f256663c6a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f256663c5f8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f25666579b0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dense', 'dense_1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].name, model.layers[2].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_2'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_2').name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00151412,  0.05424559, -0.04390296, ..., -0.01981514,\n",
       "        -0.00197704,  0.03854994],\n",
       "       [-0.01824966, -0.02495626,  0.00606195, ...,  0.04944047,\n",
       "        -0.05778001,  0.03181369],\n",
       "       [ 0.06971675, -0.04726425, -0.02204804, ..., -0.0730136 ,\n",
       "        -0.04299932, -0.01252839],\n",
       "       ...,\n",
       "       [-0.05810487,  0.05698879,  0.03344444, ...,  0.01417258,\n",
       "        -0.0647075 ,  0.02185048],\n",
       "       [ 0.01937681,  0.00589656,  0.04455777, ..., -0.06230827,\n",
       "        -0.03519905, -0.06208036],\n",
       "       [-0.05663517,  0.03391196, -0.07336944, ..., -0.04942816,\n",
       "         0.03734696, -0.06911667]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0725 14:34:45.442726 139799910520640 deprecation.py:323] From /home/kuzman/anaconda3/envs/tensorflow_2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 7s 127us/sample - loss: 0.7009 - acc: 0.7712 - val_loss: 0.5116 - val_acc: 0.8304\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 5s 100us/sample - loss: 0.4828 - acc: 0.8325 - val_loss: 0.4376 - val_acc: 0.8584\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.4367 - acc: 0.8479 - val_loss: 0.4126 - val_acc: 0.8614\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 10s 174us/sample - loss: 0.4112 - acc: 0.8553 - val_loss: 0.4001 - val_acc: 0.8648\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 8s 154us/sample - loss: 0.3919 - acc: 0.8631 - val_loss: 0.3938 - val_acc: 0.8660\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 5s 87us/sample - loss: 0.3766 - acc: 0.8675 - val_loss: 0.3794 - val_acc: 0.8678\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.3638 - acc: 0.8716 - val_loss: 0.3645 - val_acc: 0.8726\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 0.3519 - acc: 0.8742 - val_loss: 0.3613 - val_acc: 0.8762\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 6s 116us/sample - loss: 0.3413 - acc: 0.8793 - val_loss: 0.3521 - val_acc: 0.8750\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 5s 84us/sample - loss: 0.3323 - acc: 0.8822 - val_loss: 0.3393 - val_acc: 0.8804\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 6s 104us/sample - loss: 0.3241 - acc: 0.8847 - val_loss: 0.3395 - val_acc: 0.8812\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.3157 - acc: 0.8867 - val_loss: 0.3313 - val_acc: 0.8836\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.3084 - acc: 0.8900 - val_loss: 0.3286 - val_acc: 0.8814\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 4s 81us/sample - loss: 0.3023 - acc: 0.8917 - val_loss: 0.3324 - val_acc: 0.8844\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 0.2961 - acc: 0.8945 - val_loss: 0.3194 - val_acc: 0.8876\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 7s 131us/sample - loss: 0.2904 - acc: 0.8959 - val_loss: 0.3253 - val_acc: 0.8844\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 6s 103us/sample - loss: 0.2832 - acc: 0.8982 - val_loss: 0.3239 - val_acc: 0.8830\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.2783 - acc: 0.8992 - val_loss: 0.3199 - val_acc: 0.8880\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 5s 90us/sample - loss: 0.2730 - acc: 0.9007 - val_loss: 0.3190 - val_acc: 0.8844\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 6s 106us/sample - loss: 0.2692 - acc: 0.9034 - val_loss: 0.3156 - val_acc: 0.8900\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2635 - acc: 0.9052 - val_loss: 0.3111 - val_acc: 0.8878\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 6s 100us/sample - loss: 0.2587 - acc: 0.9071 - val_loss: 0.3102 - val_acc: 0.8900\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 5s 96us/sample - loss: 0.2547 - acc: 0.9088 - val_loss: 0.3383 - val_acc: 0.8812\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.2497 - acc: 0.9098 - val_loss: 0.3060 - val_acc: 0.8898\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 8s 148us/sample - loss: 0.2466 - acc: 0.9107 - val_loss: 0.3119 - val_acc: 0.8922\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 8s 141us/sample - loss: 0.2410 - acc: 0.9138 - val_loss: 0.2975 - val_acc: 0.8936\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 6s 103us/sample - loss: 0.2372 - acc: 0.9145 - val_loss: 0.3196 - val_acc: 0.8868\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.2334 - acc: 0.9157 - val_loss: 0.3147 - val_acc: 0.8902\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 7s 119us/sample - loss: 0.2290 - acc: 0.9185 - val_loss: 0.3192 - val_acc: 0.8884\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 5s 98us/sample - loss: 0.2264 - acc: 0.9186 - val_loss: 0.3017 - val_acc: 0.8926\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 48us/sample - loss: 2.4974 - acc: 0.8431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.497382470512319, 0.8431]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[42:56]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 6, 9, 2, 1, 2, 6, 4, 4, 5, 8, 2, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Shirt', 'Ankle boot', 'Shirt', 'Ankle boot', 'Pullover',\n",
       "       'Trouser', 'Pullover', 'Shirt', 'Coat', 'Coat', 'Sandal', 'Bag',\n",
       "       'Pullover', 'Pullover'], dtype='<U11')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 6, 7, 2, 1, 2, 2, 4, 4, 5, 8, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[42:56]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.8002 - mse: 0.8002 - val_loss: 13.3316 - val_mse: 13.3316\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5107 - mse: 0.5107 - val_loss: 4.4378 - val_mse: 4.4378\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4498 - mse: 0.4498 - val_loss: 0.4130 - val_mse: 0.4130\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4120 - mse: 0.4120 - val_loss: 0.3707 - val_mse: 0.3707\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4088 - mse: 0.4088 - val_loss: 0.3776 - val_mse: 0.3776\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.4287 - mse: 0.4287 - val_loss: 0.3703 - val_mse: 0.3703\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3931 - mse: 0.3931 - val_loss: 0.3803 - val_mse: 0.3803\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3868 - mse: 0.3868 - val_loss: 0.3793 - val_mse: 0.3793\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.3793 - mse: 0.3793 - val_loss: 0.3971 - val_mse: 0.3971\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3819 - mse: 0.3819 - val_loss: 0.3773 - val_mse: 0.3773\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3758 - mse: 0.3758 - val_loss: 0.3729 - val_mse: 0.3729\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3726 - mse: 0.3726 - val_loss: 0.3821 - val_mse: 0.3821\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3697 - mse: 0.3697 - val_loss: 0.3711 - val_mse: 0.3711\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.3762 - mse: 0.3762 - val_loss: 0.3467 - val_mse: 0.3467\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3638 - mse: 0.3638 - val_loss: 0.3480 - val_mse: 0.3480\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 41us/sample - loss: 0.3645 - mse: 0.3645 - val_loss: 0.3408 - val_mse: 0.3408\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 40us/sample - loss: 0.3664 - mse: 0.3664 - val_loss: 0.3521 - val_mse: 0.3521\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3621 - mse: 0.3621 - val_loss: 0.3638 - val_mse: 0.3638\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3627 - mse: 0.3627 - val_loss: 0.3324 - val_mse: 0.3324\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 43us/sample - loss: 0.3572 - mse: 0.3572 - val_loss: 0.3603 - val_mse: 0.3603\n",
      "5160/5160 [==============================] - 1s 132us/sample - loss: 0.3509 - mse: 0.3509\n"
     ]
    }
   ],
   "source": [
    "# Regression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='sgd', metrics=['mse'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=20)\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "X_new = X_test[:10]\n",
    "\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.35094264805778974, 0.35094267]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 30)           270         input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 30)           930         dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 38)           0           input_16[0][0]                   \n",
      "                                                                 dense_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 1)            39          concatenate_12[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 61us/sample - loss: 1.6490 - val_loss: 1.2961\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.6932 - val_loss: 0.6334\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.6316 - val_loss: 0.6346\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 52us/sample - loss: 0.5938 - val_loss: 0.7813\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.5604 - val_loss: 0.8127\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5389 - val_loss: 0.8115\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.5167 - val_loss: 0.4938\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4990 - val_loss: 0.4988\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4841 - val_loss: 0.4622\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4724 - val_loss: 0.4443\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4610 - val_loss: 0.4388\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.4520 - val_loss: 0.4368\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4438 - val_loss: 0.4143\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 45us/sample - loss: 0.4371 - val_loss: 0.4246\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4309 - val_loss: 0.3996\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 43us/sample - loss: 0.4256 - val_loss: 0.4041\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4208 - val_loss: 0.3918\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.4164 - val_loss: 0.3970\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4126 - val_loss: 0.3912\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 42us/sample - loss: 0.4091 - val_loss: 0.3862\n",
      "5160/5160 [==============================] - 0s 26us/sample - loss: 0.3996\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)\n",
    "# strange nan loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send only subset of features to each input\n",
    "input_A = keras.layers.Input(shape=[5])\n",
    "input_B = keras.layers.Input(shape=[6])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 1.2879 - val_loss: 3.6996\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.5403 - val_loss: 1.8152\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 49us/sample - loss: 0.4558 - val_loss: 1.4187\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 44us/sample - loss: 0.4338 - val_loss: 0.7769\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4200 - val_loss: 0.5147\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.4115 - val_loss: 0.3806\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4041 - val_loss: 0.3827\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3996 - val_loss: 0.4089\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.4152 - val_loss: 0.4003\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.4006 - val_loss: 0.7272\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.4118 - val_loss: 0.4458\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 46us/sample - loss: 0.3971 - val_loss: 0.3610\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3911 - val_loss: 0.3548\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3880 - val_loss: 0.3531\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 70us/sample - loss: 0.3842 - val_loss: 0.3820\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3792 - val_loss: 0.3479\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 55us/sample - loss: 0.3723 - val_loss: 0.3752\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.3732 - val_loss: 0.3543\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3671 - val_loss: 0.3704\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.3644 - val_loss: 0.3677\n",
      "5160/5160 [==============================] - 0s 32us/sample - loss: 0.3587\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer='sgd')\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35868523474349534"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_output\n",
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 100us/sample - loss: 0.8860 - main_output_loss: 0.7972 - aux_output_loss: 1.6826 - val_loss: 2.0425 - val_main_output_loss: 2.1478 - val_aux_output_loss: 1.0866\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 1s 69us/sample - loss: 0.5084 - main_output_loss: 0.4564 - aux_output_loss: 0.9750 - val_loss: 5.3655 - val_main_output_loss: 5.7739 - val_aux_output_loss: 1.6637\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.5440 - main_output_loss: 0.5113 - aux_output_loss: 0.8383 - val_loss: 0.9601 - val_main_output_loss: 0.7743 - val_aux_output_loss: 2.6291\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.4714 - main_output_loss: 0.4408 - aux_output_loss: 0.7471 - val_loss: 43.0137 - val_main_output_loss: 47.6713 - val_aux_output_loss: 0.8756\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 1s 54us/sample - loss: 0.5208 - main_output_loss: 0.5018 - aux_output_loss: 0.6915 - val_loss: 1.2462 - val_main_output_loss: 1.2132 - val_aux_output_loss: 1.5424\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.4404 - main_output_loss: 0.4169 - aux_output_loss: 0.6515 - val_loss: 0.4401 - val_main_output_loss: 0.4166 - val_aux_output_loss: 0.6513\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4213 - main_output_loss: 0.3992 - aux_output_loss: 0.6199 - val_loss: 0.4270 - val_main_output_loss: 0.4067 - val_aux_output_loss: 0.6103\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.4153 - main_output_loss: 0.3942 - aux_output_loss: 0.6034 - val_loss: 0.4231 - val_main_output_loss: 0.4040 - val_aux_output_loss: 0.5939\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.4076 - main_output_loss: 0.3882 - aux_output_loss: 0.5823 - val_loss: 0.4165 - val_main_output_loss: 0.3985 - val_aux_output_loss: 0.5795\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 1s 62us/sample - loss: 0.4043 - main_output_loss: 0.3858 - aux_output_loss: 0.5704 - val_loss: 0.4106 - val_main_output_loss: 0.3943 - val_aux_output_loss: 0.5571\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3975 - main_output_loss: 0.3794 - aux_output_loss: 0.5602 - val_loss: 0.4163 - val_main_output_loss: 0.4007 - val_aux_output_loss: 0.5587\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 1s 73us/sample - loss: 0.3958 - main_output_loss: 0.3780 - aux_output_loss: 0.5555 - val_loss: 0.4057 - val_main_output_loss: 0.3903 - val_aux_output_loss: 0.5433\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 1s 60us/sample - loss: 0.3888 - main_output_loss: 0.3720 - aux_output_loss: 0.5401 - val_loss: 0.3920 - val_main_output_loss: 0.3776 - val_aux_output_loss: 0.5216\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 0.3926 - main_output_loss: 0.3772 - aux_output_loss: 0.5303 - val_loss: 0.3961 - val_main_output_loss: 0.3813 - val_aux_output_loss: 0.5280\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 1s 63us/sample - loss: 0.3816 - main_output_loss: 0.3660 - aux_output_loss: 0.5229 - val_loss: 0.3721 - val_main_output_loss: 0.3576 - val_aux_output_loss: 0.5019\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3811 - main_output_loss: 0.3662 - aux_output_loss: 0.5155 - val_loss: 0.3716 - val_main_output_loss: 0.3573 - val_aux_output_loss: 0.5004\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3749 - main_output_loss: 0.3600 - aux_output_loss: 0.5099 - val_loss: 0.3739 - val_main_output_loss: 0.3598 - val_aux_output_loss: 0.5021\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 1s 66us/sample - loss: 0.3700 - main_output_loss: 0.3554 - aux_output_loss: 0.5021 - val_loss: 0.3634 - val_main_output_loss: 0.3497 - val_aux_output_loss: 0.4864\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 0.3720 - main_output_loss: 0.3582 - aux_output_loss: 0.4962 - val_loss: 0.3748 - val_main_output_loss: 0.3597 - val_aux_output_loss: 0.5101\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 1s 56us/sample - loss: 0.3650 - main_output_loss: 0.3511 - aux_output_loss: 0.4891 - val_loss: 0.3543 - val_main_output_loss: 0.3402 - val_aux_output_loss: 0.4808\n",
      "5160/5160 [==============================] - 0s 40us/sample - loss: 0.3531 - main_output_loss: 0.3407 - aux_output_loss: 0.4651\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=\"sgd\")\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35314950226813324, 0.34066918, 0.4650879)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Dynamic Models Using the Subclassing API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
