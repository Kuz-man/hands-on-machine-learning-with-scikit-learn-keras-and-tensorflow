{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hands_on_ML_chapter_11_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOHJu/LSSfDNGnr0o770nmg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuz-man/hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow/blob/master/hands_on_ML_chapter_11_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbnGXbBPBlfm"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "from tensorflow.keras.optimizers import Nadam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teZUkufqxVXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c909de7-65b7-4e74-8e32-e8e3ccc0b66d"
      },
      "source": [
        "# Build a DNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function.\n",
        "# Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset.\n",
        "# You can load it with keras.datasets.cifar10.load_​data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes,\n",
        "# so you’ll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters.\n",
        "\n",
        "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "X_train = X_train_full[:45000]\n",
        "y_train = y_train_full[:45000]\n",
        "X_valid = X_train_full[45000:]\n",
        "y_valid = y_train_full[45000:]\n",
        "\n",
        "print(y_valid.shape)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Input(shape=(32, 32, 3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "for _ in range(20):\n",
        "  model.add(Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Nadam(lr=1e-5), metrics=['acc'])\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 1)\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 100)               307300    \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_93 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_95 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_97 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_98 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_99 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_100 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_101 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_108 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_109 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 510,310\n",
            "Trainable params: 510,310\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 9.6076 - acc: 0.1224 - val_loss: 2.8969 - val_acc: 0.1290\n",
            "Epoch 2/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 2.5591 - acc: 0.1499 - val_loss: 2.3364 - val_acc: 0.1726\n",
            "Epoch 3/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 2.2397 - acc: 0.1878 - val_loss: 2.1716 - val_acc: 0.2022\n",
            "Epoch 4/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 2.1072 - acc: 0.2235 - val_loss: 2.0485 - val_acc: 0.2480\n",
            "Epoch 5/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 2.0218 - acc: 0.2535 - val_loss: 1.9968 - val_acc: 0.2682\n",
            "Epoch 6/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.9544 - acc: 0.2810 - val_loss: 1.9477 - val_acc: 0.2954\n",
            "Epoch 7/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8989 - acc: 0.3051 - val_loss: 1.8824 - val_acc: 0.3152\n",
            "Epoch 8/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8570 - acc: 0.3243 - val_loss: 1.8612 - val_acc: 0.3208\n",
            "Epoch 9/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.8206 - acc: 0.3370 - val_loss: 1.8223 - val_acc: 0.3418\n",
            "Epoch 10/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7908 - acc: 0.3496 - val_loss: 1.8083 - val_acc: 0.3384\n",
            "Epoch 11/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7685 - acc: 0.3596 - val_loss: 1.7829 - val_acc: 0.3574\n",
            "Epoch 12/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7446 - acc: 0.3660 - val_loss: 1.7836 - val_acc: 0.3454\n",
            "Epoch 13/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7248 - acc: 0.3740 - val_loss: 1.7577 - val_acc: 0.3664\n",
            "Epoch 14/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7070 - acc: 0.3837 - val_loss: 1.7440 - val_acc: 0.3720\n",
            "Epoch 15/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6912 - acc: 0.3886 - val_loss: 1.7274 - val_acc: 0.3800\n",
            "Epoch 16/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6733 - acc: 0.3958 - val_loss: 1.7378 - val_acc: 0.3822\n",
            "Epoch 17/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6599 - acc: 0.4016 - val_loss: 1.7178 - val_acc: 0.3806\n",
            "Epoch 18/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6469 - acc: 0.4057 - val_loss: 1.6969 - val_acc: 0.3920\n",
            "Epoch 19/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6318 - acc: 0.4118 - val_loss: 1.6907 - val_acc: 0.3936\n",
            "Epoch 20/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6192 - acc: 0.4167 - val_loss: 1.6792 - val_acc: 0.3998\n",
            "Epoch 21/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6089 - acc: 0.4197 - val_loss: 1.6814 - val_acc: 0.3936\n",
            "Epoch 22/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5987 - acc: 0.4261 - val_loss: 1.6768 - val_acc: 0.4042\n",
            "Epoch 23/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5835 - acc: 0.4319 - val_loss: 1.6616 - val_acc: 0.4088\n",
            "Epoch 24/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5745 - acc: 0.4352 - val_loss: 1.6658 - val_acc: 0.4062\n",
            "Epoch 25/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5637 - acc: 0.4397 - val_loss: 1.6593 - val_acc: 0.4090\n",
            "Epoch 26/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5546 - acc: 0.4422 - val_loss: 1.6696 - val_acc: 0.4054\n",
            "Epoch 27/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5463 - acc: 0.4454 - val_loss: 1.6576 - val_acc: 0.4088\n",
            "Epoch 28/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5368 - acc: 0.4501 - val_loss: 1.6517 - val_acc: 0.4096\n",
            "Epoch 29/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5257 - acc: 0.4536 - val_loss: 1.6476 - val_acc: 0.4146\n",
            "Epoch 30/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5173 - acc: 0.4568 - val_loss: 1.6564 - val_acc: 0.4112\n",
            "Epoch 31/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5097 - acc: 0.4574 - val_loss: 1.6371 - val_acc: 0.4156\n",
            "Epoch 32/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5039 - acc: 0.4602 - val_loss: 1.6307 - val_acc: 0.4224\n",
            "Epoch 33/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4951 - acc: 0.4654 - val_loss: 1.6353 - val_acc: 0.4214\n",
            "Epoch 34/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4872 - acc: 0.4666 - val_loss: 1.6300 - val_acc: 0.4204\n",
            "Epoch 35/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4796 - acc: 0.4685 - val_loss: 1.6348 - val_acc: 0.4284\n",
            "Epoch 36/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4718 - acc: 0.4726 - val_loss: 1.6280 - val_acc: 0.4252\n",
            "Epoch 37/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4642 - acc: 0.4747 - val_loss: 1.6246 - val_acc: 0.4216\n",
            "Epoch 38/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4584 - acc: 0.4763 - val_loss: 1.6210 - val_acc: 0.4248\n",
            "Epoch 39/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4508 - acc: 0.4786 - val_loss: 1.6308 - val_acc: 0.4252\n",
            "Epoch 40/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4462 - acc: 0.4814 - val_loss: 1.6302 - val_acc: 0.4176\n",
            "Epoch 41/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4390 - acc: 0.4846 - val_loss: 1.6199 - val_acc: 0.4312\n",
            "Epoch 42/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4315 - acc: 0.4877 - val_loss: 1.6283 - val_acc: 0.4266\n",
            "Epoch 43/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4253 - acc: 0.4884 - val_loss: 1.6233 - val_acc: 0.4270\n",
            "Epoch 44/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4186 - acc: 0.4924 - val_loss: 1.6188 - val_acc: 0.4250\n",
            "Epoch 45/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4153 - acc: 0.4945 - val_loss: 1.6227 - val_acc: 0.4298\n",
            "Epoch 46/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4062 - acc: 0.4956 - val_loss: 1.6293 - val_acc: 0.4310\n",
            "Epoch 47/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4023 - acc: 0.4972 - val_loss: 1.6245 - val_acc: 0.4394\n",
            "Epoch 48/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3966 - acc: 0.4988 - val_loss: 1.6153 - val_acc: 0.4402\n",
            "Epoch 49/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3887 - acc: 0.5008 - val_loss: 1.6298 - val_acc: 0.4326\n",
            "Epoch 50/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3866 - acc: 0.5031 - val_loss: 1.6193 - val_acc: 0.4384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f480bee77b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nws9W1U2lVmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b98fc12-dff8-458f-b9ab-dd86197497ab"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6212 - acc: 0.4309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6212340593338013, 0.4309000074863434]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDvXLlhrrA5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db52f3de-51ae-4d17-8fe3-018e0daa7eb4"
      },
      "source": [
        "# Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model_bn = tf.keras.Sequential()\n",
        "model_bn.add(Flatten(input_shape=(32, 32, 3)))\n",
        "for _ in range(20):\n",
        "  model_bn.add(Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
        "  model_bn.add(BatchNormalization())\n",
        "\n",
        "model_bn.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model_bn.summary()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3)\n",
        "\n",
        "model_bn.compile(loss='sparse_categorical_crossentropy', optimizer=Nadam(lr=1e-5), metrics=['acc'])\n",
        "\n",
        "model_bn.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=50, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_6 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            (None, 100)               307300    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_132 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_133 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_134 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_135 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_136 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_137 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_138 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_139 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 508,210\n",
            "Trainable params: 504,210\n",
            "Non-trainable params: 4,000\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 2.6368 - acc: 0.1334 - val_loss: 2.3841 - val_acc: 0.1762\n",
            "Epoch 2/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 2.2885 - acc: 0.1870 - val_loss: 2.3378 - val_acc: 0.2192\n",
            "Epoch 3/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 2.1579 - acc: 0.2281 - val_loss: 2.1937 - val_acc: 0.2526\n",
            "Epoch 4/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 2.0808 - acc: 0.2485 - val_loss: 2.1326 - val_acc: 0.2764\n",
            "Epoch 5/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 2.0151 - acc: 0.2726 - val_loss: 2.0242 - val_acc: 0.2854\n",
            "Epoch 6/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.9681 - acc: 0.2870 - val_loss: 1.9301 - val_acc: 0.3130\n",
            "Epoch 7/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.9284 - acc: 0.3058 - val_loss: 1.9012 - val_acc: 0.3146\n",
            "Epoch 8/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.8923 - acc: 0.3186 - val_loss: 1.9323 - val_acc: 0.3376\n",
            "Epoch 9/50\n",
            "1407/1407 [==============================] - 36s 26ms/step - loss: 1.8644 - acc: 0.3297 - val_loss: 1.8757 - val_acc: 0.3482\n",
            "Epoch 10/50\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 1.8442 - acc: 0.3362 - val_loss: 1.8447 - val_acc: 0.3626\n",
            "Epoch 11/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.8179 - acc: 0.3462 - val_loss: 1.7993 - val_acc: 0.3696\n",
            "Epoch 12/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.7990 - acc: 0.3554 - val_loss: 1.8026 - val_acc: 0.3726\n",
            "Epoch 13/50\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 1.7809 - acc: 0.3592 - val_loss: 1.7658 - val_acc: 0.3806\n",
            "Epoch 14/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.7637 - acc: 0.3684 - val_loss: 1.7438 - val_acc: 0.3882\n",
            "Epoch 15/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.7439 - acc: 0.3784 - val_loss: 1.7372 - val_acc: 0.3902\n",
            "Epoch 16/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.7336 - acc: 0.3780 - val_loss: 1.7134 - val_acc: 0.3976\n",
            "Epoch 17/50\n",
            "1407/1407 [==============================] - 36s 25ms/step - loss: 1.7172 - acc: 0.3870 - val_loss: 1.7040 - val_acc: 0.4096\n",
            "Epoch 18/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.6971 - acc: 0.3921 - val_loss: 1.6768 - val_acc: 0.4086\n",
            "Epoch 19/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.6849 - acc: 0.3996 - val_loss: 1.6720 - val_acc: 0.4092\n",
            "Epoch 20/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.6701 - acc: 0.4044 - val_loss: 1.6697 - val_acc: 0.4130\n",
            "Epoch 21/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.6555 - acc: 0.4099 - val_loss: 1.6443 - val_acc: 0.4222\n",
            "Epoch 22/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.6510 - acc: 0.4099 - val_loss: 1.6288 - val_acc: 0.4306\n",
            "Epoch 23/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.6427 - acc: 0.4139 - val_loss: 1.6270 - val_acc: 0.4334\n",
            "Epoch 24/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.6288 - acc: 0.4183 - val_loss: 1.6110 - val_acc: 0.4312\n",
            "Epoch 25/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.6242 - acc: 0.4204 - val_loss: 1.6014 - val_acc: 0.4392\n",
            "Epoch 26/50\n",
            "1407/1407 [==============================] - 35s 25ms/step - loss: 1.6141 - acc: 0.4266 - val_loss: 1.5998 - val_acc: 0.4400\n",
            "Epoch 27/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.6070 - acc: 0.4268 - val_loss: 1.6004 - val_acc: 0.4414\n",
            "Epoch 28/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.6024 - acc: 0.4283 - val_loss: 1.6001 - val_acc: 0.4322\n",
            "Epoch 29/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.5915 - acc: 0.4328 - val_loss: 1.5947 - val_acc: 0.4414\n",
            "Epoch 30/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.5845 - acc: 0.4341 - val_loss: 1.5742 - val_acc: 0.4512\n",
            "Epoch 31/50\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 1.5824 - acc: 0.4375 - val_loss: 1.5855 - val_acc: 0.4496\n",
            "Epoch 32/50\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 1.5674 - acc: 0.4407 - val_loss: 1.5617 - val_acc: 0.4516\n",
            "Epoch 33/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.5666 - acc: 0.4412 - val_loss: 1.5801 - val_acc: 0.4482\n",
            "Epoch 34/50\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 1.5579 - acc: 0.4437 - val_loss: 1.5671 - val_acc: 0.4558\n",
            "Epoch 35/50\n",
            "1407/1407 [==============================] - 33s 24ms/step - loss: 1.5547 - acc: 0.4466 - val_loss: 1.5509 - val_acc: 0.4580\n",
            "Epoch 36/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.5474 - acc: 0.4505 - val_loss: 1.5489 - val_acc: 0.4508\n",
            "Epoch 37/50\n",
            "1407/1407 [==============================] - 34s 24ms/step - loss: 1.5396 - acc: 0.4514 - val_loss: 1.5532 - val_acc: 0.4520\n",
            "Epoch 38/50\n",
            "1407/1407 [==============================] - 32s 23ms/step - loss: 1.5376 - acc: 0.4542 - val_loss: 1.5300 - val_acc: 0.4652\n",
            "Epoch 39/50\n",
            "1407/1407 [==============================] - 32s 23ms/step - loss: 1.5306 - acc: 0.4566 - val_loss: 1.5518 - val_acc: 0.4604\n",
            "Epoch 40/50\n",
            "1407/1407 [==============================] - 32s 23ms/step - loss: 1.5259 - acc: 0.4557 - val_loss: 1.5227 - val_acc: 0.4672\n",
            "Epoch 41/50\n",
            "1407/1407 [==============================] - 31s 22ms/step - loss: 1.5156 - acc: 0.4597 - val_loss: 1.5339 - val_acc: 0.4594\n",
            "Epoch 42/50\n",
            "1407/1407 [==============================] - 32s 23ms/step - loss: 1.5086 - acc: 0.4639 - val_loss: 1.5361 - val_acc: 0.4536\n",
            "Epoch 43/50\n",
            "1407/1407 [==============================] - 32s 23ms/step - loss: 1.5039 - acc: 0.4657 - val_loss: 1.5257 - val_acc: 0.4644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4813815668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxmGIZBgtCL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32fb705d-082a-4d6b-c214-c5428155d842"
      },
      "source": [
        "model_bn.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.5197 - acc: 0.4679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5196648836135864, 0.46790000796318054]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STTAdAxNtD7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb5eac81-f7bb-4927-dff3-0bb8245507cd"
      },
      "source": [
        "# Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes\n",
        "# (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.).\n",
        "\n",
        "model_selu = tf.keras.Sequential()\n",
        "model_selu.add(Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "for _ in range(20):\n",
        "  model_selu.add(Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
        "\n",
        "model_selu.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model_selu.summary()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3)\n",
        "\n",
        "model_selu.compile(loss='sparse_categorical_crossentropy', optimizer=Nadam(lr=1e-5), metrics=['acc'])\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model_selu.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=50, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_7 (Flatten)          (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense_152 (Dense)            (None, 100)               307300    \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_159 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_160 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_161 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_162 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_163 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_164 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_165 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_166 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_167 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_168 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_169 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_170 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_171 (Dense)            (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_172 (Dense)            (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 500,210\n",
            "Trainable params: 500,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 2.0595 - acc: 0.2728 - val_loss: 1.9075 - val_acc: 0.3138\n",
            "Epoch 2/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8156 - acc: 0.3538 - val_loss: 1.7975 - val_acc: 0.3488\n",
            "Epoch 3/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7128 - acc: 0.3904 - val_loss: 1.7322 - val_acc: 0.3814\n",
            "Epoch 4/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.6426 - acc: 0.4150 - val_loss: 1.6862 - val_acc: 0.3952\n",
            "Epoch 5/50\n",
            "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5908 - acc: 0.4347 - val_loss: 1.6547 - val_acc: 0.4088\n",
            "Epoch 6/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5473 - acc: 0.4519 - val_loss: 1.6292 - val_acc: 0.4182\n",
            "Epoch 7/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.5114 - acc: 0.4644 - val_loss: 1.6168 - val_acc: 0.4276\n",
            "Epoch 8/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4781 - acc: 0.4768 - val_loss: 1.6007 - val_acc: 0.4320\n",
            "Epoch 9/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4511 - acc: 0.4878 - val_loss: 1.5896 - val_acc: 0.4302\n",
            "Epoch 10/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4256 - acc: 0.4973 - val_loss: 1.5832 - val_acc: 0.4358\n",
            "Epoch 11/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4024 - acc: 0.5066 - val_loss: 1.5786 - val_acc: 0.4444\n",
            "Epoch 12/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3813 - acc: 0.5135 - val_loss: 1.5703 - val_acc: 0.4462\n",
            "Epoch 13/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3611 - acc: 0.5223 - val_loss: 1.5717 - val_acc: 0.4436\n",
            "Epoch 14/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3413 - acc: 0.5288 - val_loss: 1.5619 - val_acc: 0.4544\n",
            "Epoch 15/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3233 - acc: 0.5342 - val_loss: 1.5639 - val_acc: 0.4494\n",
            "Epoch 16/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3059 - acc: 0.5419 - val_loss: 1.5621 - val_acc: 0.4552\n",
            "Epoch 17/50\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2893 - acc: 0.5471 - val_loss: 1.5652 - val_acc: 0.4586\n",
            "Epoch 18/50\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2730 - acc: 0.5502 - val_loss: 1.5597 - val_acc: 0.4560\n",
            "Epoch 19/50\n",
            "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2572 - acc: 0.5592 - val_loss: 1.5676 - val_acc: 0.4524\n",
            "Epoch 20/50\n",
            "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2424 - acc: 0.5638 - val_loss: 1.5670 - val_acc: 0.4516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f480a119f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OP9UjOpu2u5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc6b33a-1fea-464d-b1da-0bff5dbe1cd0"
      },
      "source": [
        "model_selu.evaluate(X_test_scaled, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 1.5601 - acc: 0.4589\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5601130723953247, 0.45890000462532043]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnPg9KBDvZoT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67aaf69d-0b94-44f9-d449-1f5fd0194534"
      },
      "source": [
        "# Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout.\n",
        "\n",
        "from tensorflow.keras.layers import AlphaDropout\n",
        "\n",
        "model_selu_dr = tf.keras.Sequential()\n",
        "model_selu_dr.add(Flatten(input_shape=(32, 32, 3)))\n",
        "\n",
        "for _ in range(20):\n",
        "  model_selu_dr.add(Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
        "  model_selu_dr.add(AlphaDropout(rate=0.1))\n",
        "\n",
        "model_selu_dr.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model_selu_dr.summary()\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=3)\n",
        "\n",
        "model_selu_dr.compile(loss='sparse_categorical_crossentropy', optimizer=Nadam(lr=1e-5), metrics=['acc'])\n",
        "\n",
        "X_means = X_train.mean(axis=0)\n",
        "X_stds = X_train.std(axis=0)\n",
        "X_train_scaled = (X_train - X_means) / X_stds\n",
        "X_valid_scaled = (X_valid - X_means) / X_stds\n",
        "X_test_scaled = (X_test - X_means) / X_stds\n",
        "\n",
        "model_selu_dr.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=50, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 3072)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 100)               307300    \n",
            "_________________________________________________________________\n",
            "alpha_dropout (AlphaDropout) (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_1 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_2 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_3 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_4 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_5 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_6 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_7 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_8 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_9 (AlphaDropou (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_10 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_11 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_12 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_13 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_14 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_15 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_16 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_17 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_18 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "alpha_dropout_19 (AlphaDropo (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 500,210\n",
            "Trainable params: 500,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-87e4d6fe58f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel_selu_dr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNadam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mX_means\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mX_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_means\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX_stds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnuoyyKevxSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "eb9dfee8-391c-4f5a-d966-66e222f812ed"
      },
      "source": [
        "model_selu_dr.evaluate(X_test_scaled, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-76691d0bf01c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_selu_dr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_selu_dr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrtjBM9-vyWV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}